kafka1 {

    # topic
    topic=user_behavior
    # 集群地址
    # --broker-list 连接一台与多台有区别么？ 连接一台，是生产消息只能存储在这个一台分区上吗？
    # 连接多台只是保证其中一台挂了，producer还能连接上kafka集群，producer生产的消息还是会以消息指定的分区或者key或者轮询或者随机的存在kafka集群的某个节点上
    bootstrap.servers="node1:9092"
    # 消费者组id
    group.id=flink
    # latest有offset记录从记录位置开始消费,没有记录从最新的/最后的消息开始消费
    # earliest有offset记录从记录位置开始消费,没有记录从最早的/最开始的消息开始消费
    auto.offset.reset=latest
    # 会开启一个后台线程每隔5s检测一下Kafka的分区情况,实现动态分区检测
    flink.partition-discovery.interval-millis=5000
    # 自动提交(提交到默认主题,后续学习了Checkpoint后随着Checkpoint存储在Checkpoint和默认主题中)
    enable.auto.commit=true
    # 自动提交的时间间隔
    auto.commit.interval.ms=2000
}

kafka2 {
        # topic
        topic=user_behavior
        # 集群地址
        bootstrap.servers="node2:9092"
        # 消费者组id
        group.id=flink
        # latest有offset记录从记录位置开始消费,没有记录从最新的/最后的消息开始消费
        # earliest有offset记录从记录位置开始消费,没有记录从最早的/最开始的消息开始消费
        auto.offset.reset=latest
        # 会开启一个后台线程每隔5s检测一下Kafka的分区情况,实现动态分区检测
        flink.partition-discovery.interval-millis=5000
        # 自动提交(提交到默认主题,后续学习了Checkpoint后随着Checkpoint存储在Checkpoint和默认主题中)
        enable.auto.commit=true
        # 自动提交的时间间隔
        auto.commit.interval.ms=2000
}